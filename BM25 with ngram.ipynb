{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1VqklpKGeKMnY0Ju15QMjeYlrxy5MK1KE","timestamp":1734592282913},{"file_id":"1GCUfRLubX5LUFrzxH-JpkE-K7iu_KKe9","timestamp":1734516889683},{"file_id":"1QHtK7l7M8kixJ6XCM-NFKmKKg6AP6QHs","timestamp":1734437013334},{"file_id":"1MarAXFCIA1Y_Z3SpG3Bg6j1OtSgGVNE3","timestamp":1734239109402},{"file_id":"1KeTeMxQdl4TDiHxaTFn9Z4BgnaRqWuzy","timestamp":1734237352881}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# BM25L"],"metadata":{"id":"RlGP018nzmtF"}},{"cell_type":"markdown","source":["## Simple"],"metadata":{"id":"U-YlkJtxlOQi"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import warnings\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","from nltk.corpus import stopwords\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","from collections import defaultdict\n","import math\n","\n","warnings.filterwarnings(\"ignore\")\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","\n","lyrics_df = pd.read_excel('/content/databersih.xlsx')\n","ground_truth_df = pd.read_excel('/content/GT UAS NLP_simple.xlsx')\n","\n","stemmer = PorterStemmer()\n","\n","remove_words = [\"song\", \"with\", \"lyrics\", \"from\", \"the\", \"album\", \"released\",\n","               \"in\", \"before\", \"after\", \"since\", \"s\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734556837697,"user_tz":-420,"elapsed":2085,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"85248d19-7f87-4337-ed05-851e4a7bd927","id":"RIs5Wt_AlJwm"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"code","source":["def clean_lyrics(text):\n","    if isinstance(text, str):\n","        text = re.sub(r'\\[.*?\\]', '', text)\n","        text = re.sub(r'\\(.*?\\)', '', text)\n","        text = re.sub(r'[^\\w\\s]', '', text)\n","        text = re.sub(r'\\d+', '', text)\n","        text = text.lower()\n","        tokens = word_tokenize(text)\n","        tokens = [stemmer.stem(word) for word in tokens if word not in remove_words]\n","        text = ' '.join(tokens)\n","    return text\n","\n","lyrics_df['Processed_Lyrics'] = lyrics_df['lyrics'].apply(clean_lyrics)\n","\n","print(\"\\nCleaned Lyrics Sample:\")\n","print(lyrics_df[['title', 'Processed_Lyrics']].head())\n","\n","def parse_song_ids(song_id_entry):\n","    if pd.isnull(song_id_entry):\n","        return []\n","    if isinstance(song_id_entry, int):\n","        return [song_id_entry]\n","    if isinstance(song_id_entry, float) and np.isnan(song_id_entry):\n","        return []\n","    song_id_str = str(song_id_entry)\n","    return [int(id_.strip()) for id_ in song_id_str.split(',') if id_.strip().isdigit()]\n","\n","ground_truth_df['Relevant_Song_IDs'] = ground_truth_df['song_id'].apply(parse_song_ids)\n","ground_truth_df = ground_truth_df[ground_truth_df['Relevant_Song_IDs'].map(len) > 0].reset_index(drop=True)\n","print(\"\\nParsed Ground Truth:\")\n","print(ground_truth_df[['query', 'Relevant_Song_IDs', 'total']].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734556878641,"user_tz":-420,"elapsed":40946,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"5a08b7b8-0099-4065-80d4-13c590d59350","id":"cCPkJ_VFlJwn"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Cleaned Lyrics Sample:\n","                   title                                   Processed_Lyrics\n","0      Chasing Pavements  ive made up my mind dont need to think it over...\n","1          Cold Shoulder  you say it all my head and thing i think just ...\n","2         Hometown Glory  ive been walk same way as i did miss out crack...\n","3  Make You Feel My Love  when rain is blow your face and whole world is...\n","4                My Same  aye aye ayeay aye aye ayeay aye aye ayeay aye ...\n","\n","Parsed Ground Truth:\n","           query                                  Relevant_Song_IDs  total\n","0    love you in          [129, 1433, 1977, 2978, 3214, 3320, 4514]      7\n","1   home tonight  [561, 1019, 1455, 1671, 1686, 2428, 2434, 3126...     12\n","2  something new  [20, 484, 671, 783, 999, 1463, 2556, 2607, 264...     18\n","3     i held you                             [44, 1520, 4082, 4503]      4\n","4  stars tonight                                   [95, 2142, 3177]      3\n"]}]},{"cell_type":"markdown","source":["### BM25 Implementation\n"],"metadata":{"id":"63uTJp_Nlpn-"}},{"cell_type":"code","source":["class BM25:\n","    def __init__(self, corpus, k1=1.5, b=0.75):\n","        self.corpus = corpus\n","        self.k1 = k1\n","        self.b = b\n","        self.avgdl = sum(len(doc.split()) for doc in corpus) / len(corpus)\n","        self.doc_len = [len(doc.split()) for doc in corpus]\n","        self.term_freq = []\n","        self.doc_freq = defaultdict(int)\n","        self.idf = {}\n","        self._initialize()\n","\n","    def _initialize(self):\n","        for doc in self.corpus:\n","            tf = {}\n","            words = doc.split()\n","            for w in words:\n","                tf[w] = tf.get(w, 0) + 1\n","            self.term_freq.append(tf)\n","            for word in set(words):\n","                self.doc_freq[word] += 1\n","\n","        N = len(self.corpus)\n","        for word, df in self.doc_freq.items():\n","            self.idf[word] = math.log((N - df + 0.5) / (df + 0.5) + 1)\n","\n","    def score(self, query, doc_index):\n","        score = 0.0\n","        words = query.split()\n","        tf = self.term_freq[doc_index]\n","        dl = self.doc_len[doc_index]\n","        for w in words:\n","            if w in self.idf:\n","                f = tf.get(w, 0)\n","                denom = f + self.k1 * (1 - self.b + self.b * (dl / self.avgdl))\n","                score += self.idf[w] * ((f * (self.k1 + 1)) / denom)\n","        return score\n","\n","    def get_scores(self, query):\n","        scores = []\n","        for i in range(len(self.corpus)):\n","            scores.append(self.score(query, i))\n","        return scores\n"],"metadata":{"id":"BcOb9TSZlJwo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing Queries\n"],"metadata":{"id":"tCStRJdGlwf9"}},{"cell_type":"code","source":["def preprocess_query(query, lyrics_df):\n","    if isinstance(query, str):\n","        artist_list = lyrics_df['artist'].str.lower().unique()\n","        album_list = lyrics_df['album'].str.lower().unique()\n","        year_list = lyrics_df['year'].unique()\n","        for artist in artist_list:\n","            query = re.sub(r'\\b' + re.escape(artist) + r'\\b', '', query, flags=re.IGNORECASE)\n","        for album in album_list:\n","            query = re.sub(r'\\b' + re.escape(album) + r'\\b', '', query, flags=re.IGNORECASE)\n","        for year in year_list:\n","            query = re.sub(r'\\b' + re.escape(str(year)) + r'\\b', '', query)\n","\n","        query = re.sub(r'[^\\w\\s]', '', query)\n","        query = re.sub(r'\\d+', '', query)\n","        query = query.lower()\n","        tokens = word_tokenize(query)\n","        tokens = [stemmer.stem(word) for word in tokens if word not in remove_words]\n","        return ' '.join(tokens)\n","    return query\n","\n","ground_truth_df['Processed_Query'] = ground_truth_df['query'].apply(lambda q: preprocess_query(q, lyrics_df))\n"],"metadata":{"id":"CH55HXWAlJwo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Helper Functions for N-grams and Evaluation\n"],"metadata":{"id":"IxX-wGGFl4fK"}},{"cell_type":"code","source":["def generate_ngrams(query, n):\n","    words = query.split()\n","    return [' '.join(words[i:i + n]) for i in range(len(words) - n + 1)]\n","\n","def precision_at_k(y_true, y_pred, k):\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","    sorted_indices = np.argsort(y_pred)[::-1]\n","    top_k_indices = sorted_indices[:k]\n","    top_k_truth = y_true[top_k_indices]\n","    return np.sum(top_k_truth) / k\n","\n","def average_precision_func(y_true, y_pred):\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","    sorted_indices = np.argsort(y_pred)[::-1]\n","    y_true_sorted = y_true[sorted_indices]\n","\n","    relevant = 0\n","    precision_sum = 0\n","    for i, val in enumerate(y_true_sorted):\n","        if val == 1:\n","            relevant += 1\n","            precision_sum += relevant / (i + 1)\n","    return precision_sum / np.sum(y_true) if np.sum(y_true) > 0 else 0"],"metadata":{"id":"Z5YEnbD5lJwo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### RRF Fusion Function\n"],"metadata":{"id":"ZQm95o0Ko0B1"}},{"cell_type":"code","source":["def rrf_fusion(ranked_lists, rrf_k=60):\n","    \"\"\"\n","    Perform Reciprocal Rank Fusion (RRF) on multiple ranked lists.\n","\n","    Parameters:\n","    - ranked_lists: List of lists, where each sublist contains document IDs ordered by relevance.\n","    - rrf_k: Constant to control the influence of rank.\n","\n","    Returns:\n","    - fused_docs: List of document IDs ordered by their RRF scores.\n","    \"\"\"\n","    rrf_scores = defaultdict(float)\n","    for ranked_list in ranked_lists:\n","        for rank, doc_id in enumerate(ranked_list):\n","            rrf_scores[doc_id] += 1.0 / (rrf_k + rank + 1)\n","    fused_ranking = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n","    fused_docs = [doc_id for doc_id, score in fused_ranking]\n","    return fused_docs\n"],"metadata":{"id":"WcgGZzN7ozJn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Main Retrieval and Evaluation\n"],"metadata":{"id":"ljdMVvmimRJg"}},{"cell_type":"code","source":["corpus = lyrics_df['Processed_Lyrics'].tolist()\n","bm25 = BM25(corpus)\n","\n","song_id_to_index = {song_id: idx for idx, song_id in enumerate(lyrics_df['id'])}\n","\n","all_ngrams_results = []\n","\n","query_retrievals = defaultdict(lambda: defaultdict(list))\n","\n","for n in range(1, 6):\n","    print(f\"Evaluating {n}-gram approach...\")\n","    evaluation_results = []\n","\n","    for _, row in ground_truth_df.iterrows():\n","        query = row['Processed_Query']\n","        relevant_ids = row['Relevant_Song_IDs']\n","\n","        ngrams = generate_ngrams(query, n)\n","        if not ngrams:\n","            evaluation_results.append({\n","                'Query': row['query'],\n","                'N-gram': n,\n","                'Precision': 0.0,\n","                'Recall': 0.0,\n","                'F1-Score': 0.0,\n","                'Precision@3': 0.0,\n","                'Precision@6': 0.0,\n","                'Precision@10': 0.0,\n","                'Average Precision': 0.0\n","            })\n","            continue\n","\n","        doc_scores = np.zeros(len(corpus))\n","        for ng in ngrams:\n","            scores = bm25.get_scores(ng)\n","            doc_scores += np.array(scores)\n","\n","        y_true = [1 if lyrics_df.iloc[i]['id'] in relevant_ids else 0 for i in range(len(corpus))]\n","        y_pred = doc_scores\n","\n","        threshold = np.median(y_pred)\n","        binary_pred = y_pred >= threshold\n","\n","        precision = precision_score(y_true, binary_pred, zero_division=0)\n","        recall = recall_score(y_true, binary_pred, zero_division=0)\n","        f1 = f1_score(y_true, binary_pred, zero_division=0)\n","        p_at_3 = precision_at_k(y_true, y_pred, k=3)\n","        p_at_6 = precision_at_k(y_true, y_pred, k=6)\n","        p_at_10 = precision_at_k(y_true, y_pred, k=10)\n","        ap = average_precision_func(y_true, y_pred)\n","\n","        evaluation_results.append({\n","            'Query': row['query'],\n","            'N-gram': n,\n","            'Precision': precision,\n","            'Recall': recall,\n","            'F1-Score': f1,\n","            'Precision@3': p_at_3,\n","            'Precision@6': p_at_6,\n","            'Precision@10': p_at_10,\n","            'Average Precision': ap\n","        })\n","\n","        sorted_doc_indices = np.argsort(doc_scores)[-top_k:][::-1]\n","        retrieved_docs = lyrics_df.iloc[sorted_doc_indices]['id'].tolist()\n","        query_retrievals[row['query']][n] = retrieved_docs\n","\n","    evaluation_df = pd.DataFrame(evaluation_results)\n","    print(evaluation_df.head())\n","\n","    macro_results = {\n","        \"Metric\": [\n","            \"Precision\",\n","            \"Recall\",\n","            \"F1-Score\",\n","            \"Precision@3\",\n","            \"Precision@6\",\n","            \"Precision@10\",\n","            \"Average Precision\"\n","        ],\n","        \"Macro Average\": [\n","            evaluation_df['Precision'].mean(),\n","            evaluation_df['Recall'].mean(),\n","            evaluation_df['F1-Score'].mean(),\n","            evaluation_df['Precision@3'].mean(),\n","            evaluation_df['Precision@6'].mean(),\n","            evaluation_df['Precision@10'].mean(),\n","            evaluation_df['Average Precision'].mean()\n","        ]\n","    }\n","    macro_df = pd.DataFrame(macro_results)\n","    macro_df['N-gram'] = n\n","    print(f\"\\nMacro Averages for {n}-grams:\")\n","    print(macro_df)\n","\n","    evaluation_df.to_excel(f'evaluation_bm25_{n}gram.xlsx', index=False)\n","    macro_df.to_excel(f'macro_averages_{n}gram.xlsx', index=False)\n","    print(f\"\\nSaved evaluation_bm25_{n}gram.xlsx and macro_averages_{n}gram.xlsx\")\n","\n","    macro_df['N-gram'] = n\n","    all_ngrams_results.append(macro_df)\n","\n","combined_macro = pd.concat(all_ngrams_results, ignore_index=True)\n","combined_macro.to_excel('combined_macro_averages_all_ngrams.xlsx', index=False)\n","print(\"\\nAll combined macro averages have been saved to 'combined_macro_averages_all_ngrams.xlsx'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734556903845,"user_tz":-420,"elapsed":23661,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"463f9a8f-2a13-4c18-a11a-d5e1c5adfd22","id":"7wf2b4pDlJwo"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating 1-gram approach...\n","           Query  N-gram  Precision    Recall  F1-Score  Precision@3  \\\n","0    love you in       1   0.002036  0.714286  0.004060     0.000000   \n","1   home tonight       1   0.002443  1.000000  0.004874     0.000000   \n","2  something new       1   0.003664  1.000000  0.007302     0.666667   \n","3     i held you       1   0.001629  1.000000  0.003252     0.333333   \n","4  stars tonight       1   0.000611  1.000000  0.001221     0.333333   \n","\n","   Precision@6  Precision@10  Average Precision  \n","0     0.000000           0.0           0.003241  \n","1     0.166667           0.3           0.162615  \n","2     0.500000           0.4           0.327808  \n","3     0.166667           0.1           0.166020  \n","4     0.500000           0.3           0.666667  \n","\n","Macro Averages for 1-grams:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.001873       1\n","1             Recall       0.988571       1\n","2           F1-Score       0.003737       1\n","3        Precision@3       0.333333       1\n","4        Precision@6       0.226667       1\n","5       Precision@10       0.168000       1\n","6  Average Precision       0.300272       1\n","\n","Saved evaluation_bm25_1gram.xlsx and macro_averages_1gram.xlsx\n","Evaluating 2-gram approach...\n","           Query  N-gram  Precision  Recall  F1-Score  Precision@3  \\\n","0    love you in       2   0.000000     0.0  0.000000     0.000000   \n","1   home tonight       2   0.002443     1.0  0.004874     0.000000   \n","2  something new       2   0.003664     1.0  0.007302     0.666667   \n","3     i held you       2   0.001629     1.0  0.003252     0.333333   \n","4  stars tonight       2   0.000611     1.0  0.001221     0.333333   \n","\n","   Precision@6  Precision@10  Average Precision  \n","0     0.000000           0.0           0.000000  \n","1     0.166667           0.3           0.162615  \n","2     0.500000           0.4           0.327808  \n","3     0.166667           0.1           0.165169  \n","4     0.500000           0.3           0.666667  \n","\n","Macro Averages for 2-grams:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.001743       2\n","1             Recall       0.920000       2\n","2           F1-Score       0.003477       2\n","3        Precision@3       0.266667       2\n","4        Precision@6       0.193333       2\n","5       Precision@10       0.144000       2\n","6  Average Precision       0.254641       2\n","\n","Saved evaluation_bm25_2gram.xlsx and macro_averages_2gram.xlsx\n","Evaluating 3-gram approach...\n","           Query  N-gram  Precision  Recall  F1-Score  Precision@3  \\\n","0    love you in       3   0.000000     0.0  0.000000     0.000000   \n","1   home tonight       3   0.000000     0.0  0.000000     0.000000   \n","2  something new       3   0.000000     0.0  0.000000     0.000000   \n","3     i held you       3   0.001629     1.0  0.003252     0.333333   \n","4  stars tonight       3   0.000000     0.0  0.000000     0.000000   \n","\n","   Precision@6  Precision@10  Average Precision  \n","0     0.000000           0.0            0.00000  \n","1     0.000000           0.0            0.00000  \n","2     0.000000           0.0            0.00000  \n","3     0.166667           0.1            0.16602  \n","4     0.000000           0.0            0.00000  \n","\n","Macro Averages for 3-grams:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.001124       3\n","1             Recall       0.560000       3\n","2           F1-Score       0.002242       3\n","3        Precision@3       0.133333       3\n","4        Precision@6       0.080000       3\n","5       Precision@10       0.056000       3\n","6  Average Precision       0.118690       3\n","\n","Saved evaluation_bm25_3gram.xlsx and macro_averages_3gram.xlsx\n","Evaluating 4-gram approach...\n","           Query  N-gram  Precision  Recall  F1-Score  Precision@3  \\\n","0    love you in       4        0.0     0.0       0.0          0.0   \n","1   home tonight       4        0.0     0.0       0.0          0.0   \n","2  something new       4        0.0     0.0       0.0          0.0   \n","3     i held you       4        0.0     0.0       0.0          0.0   \n","4  stars tonight       4        0.0     0.0       0.0          0.0   \n","\n","   Precision@6  Precision@10  Average Precision  \n","0          0.0           0.0                0.0  \n","1          0.0           0.0                0.0  \n","2          0.0           0.0                0.0  \n","3          0.0           0.0                0.0  \n","4          0.0           0.0                0.0  \n","\n","Macro Averages for 4-grams:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.000195       4\n","1             Recall       0.120000       4\n","2           F1-Score       0.000390       4\n","3        Precision@3       0.040000       4\n","4        Precision@6       0.020000       4\n","5       Precision@10       0.016000       4\n","6  Average Precision       0.034416       4\n","\n","Saved evaluation_bm25_4gram.xlsx and macro_averages_4gram.xlsx\n","Evaluating 5-gram approach...\n","           Query  N-gram  Precision  Recall  F1-Score  Precision@3  \\\n","0    love you in       5        0.0     0.0       0.0          0.0   \n","1   home tonight       5        0.0     0.0       0.0          0.0   \n","2  something new       5        0.0     0.0       0.0          0.0   \n","3     i held you       5        0.0     0.0       0.0          0.0   \n","4  stars tonight       5        0.0     0.0       0.0          0.0   \n","\n","   Precision@6  Precision@10  Average Precision  \n","0          0.0           0.0                0.0  \n","1          0.0           0.0                0.0  \n","2          0.0           0.0                0.0  \n","3          0.0           0.0                0.0  \n","4          0.0           0.0                0.0  \n","\n","Macro Averages for 5-grams:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.000049       5\n","1             Recall       0.040000       5\n","2           F1-Score       0.000098       5\n","3        Precision@3       0.000000       5\n","4        Precision@6       0.000000       5\n","5       Precision@10       0.000000       5\n","6  Average Precision       0.000181       5\n","\n","Saved evaluation_bm25_5gram.xlsx and macro_averages_5gram.xlsx\n","\n","All combined macro averages have been saved to 'combined_macro_averages_all_ngrams.xlsx'.\n"]}]},{"cell_type":"code","source":["print(\"\\nStarting Reciprocal Rank Fusion (RRF) Evaluation...\")\n","\n","rrf_evaluations = []\n","\n","for _, row in ground_truth_df.iterrows():\n","    query = row['Processed_Query']\n","    original_query = row['query']\n","    relevant_ids = set(row['Relevant_Song_IDs'])\n","\n","    ranked_lists = []\n","    for n in range(1, 6):\n","        retrieved_docs = query_retrievals[original_query].get(n, [])\n","        ranked_lists.append(retrieved_docs)\n","\n","    fused_docs = rrf_fusion(ranked_lists, rrf_k=60)\n","\n","    y_true = [1 if lyrics_df.iloc[i]['id'] in relevant_ids else 0 for i in range(len(corpus))]\n","    y_pred = [1 if doc_id in fused_docs[:top_k] else 0 for doc_id in lyrics_df['id']]\n","\n","    precision = precision_score(y_true, y_pred, zero_division=0)\n","    recall = recall_score(y_true, y_pred, zero_division=0)\n","    f1 = f1_score(y_true, y_pred, zero_division=0)\n","\n","\n","    p_at_3 = precision_at_k(y_true, [lyrics_df.iloc[song_id_to_index[doc_id]]['id'] for doc_id in fused_docs], k=3)\n","    p_at_6 = precision_at_k(y_true, [lyrics_df.iloc[song_id_to_index[doc_id]]['id'] for doc_id in fused_docs], k=6)\n","    p_at_10 = precision_at_k(y_true, [lyrics_df.iloc[song_id_to_index[doc_id]]['id'] for doc_id in fused_docs], k=10)\n","\n","    fused_scores = {doc_id: score for score, doc_id in enumerate(fused_docs, start=1)}\n","    ap = average_precision_func(\n","        [1 if doc_id in relevant_ids else 0 for doc_id in lyrics_df['id']],\n","        [fused_scores.get(doc_id, 0) for doc_id in lyrics_df['id']]\n","    )\n","\n","    rrf_evaluations.append({\n","        'Query': original_query,\n","        'Precision': precision,\n","        'Recall': recall,\n","        'F1': f1,\n","        'Precision@3': p_at_3,\n","        'Precision@6': p_at_6,\n","        'Precision@10': p_at_10,\n","        'Average Precision': ap\n","    })\n","\n","rrf_df = pd.DataFrame(rrf_evaluations)\n","print(\"\\nRRF Fused Evaluation Results:\")\n","print(rrf_df.head())\n","\n","rrf_macro_results = {\n","    \"Metric\": [\n","        \"Precision\",\n","        \"Recall\",\n","        \"F1\",\n","        \"Precision@3\",\n","        \"Precision@6\",\n","        \"Precision@10\",\n","        \"Average Precision\"\n","    ],\n","    \"Macro Average\": [\n","        rrf_df['Precision'].mean(),\n","        rrf_df['Recall'].mean(),\n","        rrf_df['F1'].mean(),\n","        rrf_df['Precision@3'].mean(),\n","        rrf_df['Precision@6'].mean(),\n","        rrf_df['Precision@10'].mean(),\n","        rrf_df['Average Precision'].mean()\n","    ]\n","}\n","rrf_macro_df = pd.DataFrame(rrf_macro_results)\n","rrf_macro_df['N-gram'] = 'RRF Fusion'\n","print(\"\\nMacro Averages for RRF Fusion:\")\n","print(rrf_macro_df)\n","\n","rrf_df.to_excel('evaluation_bm25_rrf_fusion.xlsx', index=False)\n","rrf_macro_df.to_excel('macro_averages_rrf_fusion.xlsx', index=False)\n","print(\"\\nRRF Fused evaluation results have been saved to 'evaluation_bm25_rrf_fusion.xlsx'.\")\n","print(\"Macro averages for RRF Fusion have been saved to 'macro_averages_rrf_fusion.xlsx'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zHuvVt0ypBvK","executionInfo":{"status":"ok","timestamp":1734556912368,"user_tz":-420,"elapsed":8532,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"1a6a6b58-93f9-4077-c226-91042f48a7ab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting Reciprocal Rank Fusion (RRF) Evaluation...\n","\n","RRF Fused Evaluation Results:\n","           Query  Precision    Recall        F1  Precision@3  Precision@6  \\\n","0    love you in        0.0  0.000000  0.000000          0.0          0.0   \n","1   home tonight        0.3  0.250000  0.272727          0.0          0.0   \n","2  something new        0.4  0.222222  0.285714          0.0          0.0   \n","3     i held you        0.1  0.250000  0.142857          0.0          0.0   \n","4  stars tonight        0.3  1.000000  0.461538          0.0          0.0   \n","\n","   Precision@10  Average Precision  \n","0           0.0           0.001525  \n","1           0.0           0.215311  \n","2           0.0           0.075769  \n","3           0.0           0.032119  \n","4           0.0           0.261905  \n","\n","Macro Averages for RRF Fusion:\n","              Metric  Macro Average      N-gram\n","0          Precision       0.168000  RRF Fusion\n","1             Recall       0.344270  RRF Fusion\n","2                 F1       0.207371  RRF Fusion\n","3        Precision@3       0.000000  RRF Fusion\n","4        Precision@6       0.000000  RRF Fusion\n","5       Precision@10       0.000000  RRF Fusion\n","6  Average Precision       0.091568  RRF Fusion\n","\n","RRF Fused evaluation results have been saved to 'evaluation_bm25_rrf_fusion.xlsx'.\n","Macro averages for RRF Fusion have been saved to 'macro_averages_rrf_fusion.xlsx'.\n"]}]},{"cell_type":"markdown","source":["## Complex"],"metadata":{"id":"H_PWxJjGlM0E"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import warnings\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","from nltk.corpus import stopwords\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","from collections import defaultdict\n","import math\n","\n","warnings.filterwarnings(\"ignore\")\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","\n","lyrics_df = pd.read_excel('/content/databersih.xlsx')\n","ground_truth_df = pd.read_excel('/content/GT UAS NLP_complex.xlsx')\n","\n","stemmer = PorterStemmer()\n","\n","remove_words = [\"song\", \"with\", \"lyrics\", \"from\", \"the\", \"album\", \"released\",\n","               \"in\", \"before\", \"after\", \"since\", \"s\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734556913011,"user_tz":-420,"elapsed":652,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"851603b6-75fa-4c23-a2dc-c994d48ac25b","id":"SBG0eu2dpKi7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"code","source":["def clean_lyrics(text):\n","    if isinstance(text, str):\n","        text = re.sub(r'\\[.*?\\]', '', text)\n","        text = re.sub(r'\\(.*?\\)', '', text)\n","        text = re.sub(r'[^\\w\\s]', '', text)\n","        text = re.sub(r'\\d+', '', text)\n","        text = text.lower()\n","        tokens = word_tokenize(text)\n","        tokens = [stemmer.stem(word) for word in tokens if word not in remove_words]\n","        text = ' '.join(tokens)\n","    return text\n","\n","lyrics_df['Processed_Lyrics'] = lyrics_df['lyrics'].apply(clean_lyrics)\n","\n","print(\"\\nCleaned Lyrics Sample:\")\n","print(lyrics_df[['title', 'Processed_Lyrics']].head())\n","\n","def parse_song_ids(song_id_entry):\n","    if pd.isnull(song_id_entry):\n","        return []\n","    if isinstance(song_id_entry, int):\n","        return [song_id_entry]\n","    if isinstance(song_id_entry, float) and np.isnan(song_id_entry):\n","        return []\n","    song_id_str = str(song_id_entry)\n","    return [int(id_.strip()) for id_ in song_id_str.split(',') if id_.strip().isdigit()]\n","\n","ground_truth_df['Relevant_Song_IDs'] = ground_truth_df['song_id'].apply(parse_song_ids)\n","ground_truth_df = ground_truth_df[ground_truth_df['Relevant_Song_IDs'].map(len) > 0].reset_index(drop=True)\n","print(\"\\nParsed Ground Truth:\")\n","print(ground_truth_df[['query', 'Relevant_Song_IDs', 'total']].head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734556955833,"user_tz":-420,"elapsed":42826,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"8d4c4dd8-c7f0-46f9-cd44-b8c64fc1afcc","id":"fYjLOKxfpKi8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Cleaned Lyrics Sample:\n","                   title                                   Processed_Lyrics\n","0      Chasing Pavements  ive made up my mind dont need to think it over...\n","1          Cold Shoulder  you say it all my head and thing i think just ...\n","2         Hometown Glory  ive been walk same way as i did miss out crack...\n","3  Make You Feel My Love  when rain is blow your face and whole world is...\n","4                My Same  aye aye ayeay aye aye ayeay aye aye ayeay aye ...\n","\n","Parsed Ground Truth:\n","                                               query Relevant_Song_IDs  total\n","0               Adele's song with lyrics love you in            [1433]      1\n","1    Billie Eilish's song with lyrics stick together             [227]      1\n","2              Bruno Mars' song with lyrics kiss you            [2129]      1\n","3    Jennifer Lopez's song with lyrics you feel left             [788]      1\n","4  Song released in 2024 with lyrics hopeless rom...            [3019]      1\n"]}]},{"cell_type":"markdown","source":["### BM25 Implementation\n"],"metadata":{"id":"jYRLNzYspKi9"}},{"cell_type":"code","source":["class BM25:\n","    def __init__(self, corpus, k1=1.5, b=0.75):\n","        self.corpus = corpus\n","        self.k1 = k1\n","        self.b = b\n","        self.avgdl = sum(len(doc.split()) for doc in corpus) / len(corpus)\n","        self.doc_len = [len(doc.split()) for doc in corpus]\n","        self.term_freq = []\n","        self.doc_freq = defaultdict(int)\n","        self.idf = {}\n","        self._initialize()\n","\n","    def _initialize(self):\n","        for doc in self.corpus:\n","            tf = {}\n","            words = doc.split()\n","            for w in words:\n","                tf[w] = tf.get(w, 0) + 1\n","            self.term_freq.append(tf)\n","            for word in set(words):\n","                self.doc_freq[word] += 1\n","\n","        N = len(self.corpus)\n","        for word, df in self.doc_freq.items():\n","            self.idf[word] = math.log((N - df + 0.5) / (df + 0.5) + 1)\n","\n","    def score(self, query, doc_index):\n","        score = 0.0\n","        words = query.split()\n","        tf = self.term_freq[doc_index]\n","        dl = self.doc_len[doc_index]\n","        for w in words:\n","            if w in self.idf:\n","                f = tf.get(w, 0)\n","                denom = f + self.k1 * (1 - self.b + self.b * (dl / self.avgdl))\n","                score += self.idf[w] * ((f * (self.k1 + 1)) / denom)\n","        return score\n","\n","    def get_scores(self, query):\n","        scores = []\n","        for i in range(len(self.corpus)):\n","            scores.append(self.score(query, i))\n","        return scores\n"],"metadata":{"id":"NfaEYi8DpKi9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Preprocessing Queries\n"],"metadata":{"id":"fEC4-djQpKi9"}},{"cell_type":"code","source":["def preprocess_query(query, lyrics_df):\n","    if isinstance(query, str):\n","        artist_list = lyrics_df['artist'].str.lower().unique()\n","        album_list = lyrics_df['album'].str.lower().unique()\n","        year_list = lyrics_df['year'].unique()\n","        for artist in artist_list:\n","            query = re.sub(r'\\b' + re.escape(artist) + r'\\b', '', query, flags=re.IGNORECASE)\n","        for album in album_list:\n","            query = re.sub(r'\\b' + re.escape(album) + r'\\b', '', query, flags=re.IGNORECASE)\n","        for year in year_list:\n","            query = re.sub(r'\\b' + re.escape(str(year)) + r'\\b', '', query)\n","\n","        query = re.sub(r'[^\\w\\s]', '', query)\n","        query = re.sub(r'\\d+', '', query)\n","        query = query.lower()\n","        tokens = word_tokenize(query)\n","        tokens = [stemmer.stem(word) for word in tokens if word not in remove_words]\n","        return ' '.join(tokens)\n","    return query\n","\n","ground_truth_df['Processed_Query'] = ground_truth_df['query'].apply(lambda q: preprocess_query(q, lyrics_df))\n"],"metadata":{"id":"o6KTnueFpKi9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Helper Functions for N-grams and Evaluation\n"],"metadata":{"id":"tUonLnHgpKi9"}},{"cell_type":"code","source":["def generate_ngrams(query, n):\n","    words = query.split()\n","    return [' '.join(words[i:i + n]) for i in range(len(words) - n + 1)]\n","\n","def precision_at_k(y_true, y_pred, k):\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","    sorted_indices = np.argsort(y_pred)[::-1]\n","    top_k_indices = sorted_indices[:k]\n","    top_k_truth = y_true[top_k_indices]\n","    return np.sum(top_k_truth) / k\n","\n","def average_precision_func(y_true, y_pred):\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","    sorted_indices = np.argsort(y_pred)[::-1]\n","    y_true_sorted = y_true[sorted_indices]\n","\n","    relevant = 0\n","    precision_sum = 0\n","    for i, val in enumerate(y_true_sorted):\n","        if val == 1:\n","            relevant += 1\n","            precision_sum += relevant / (i + 1)\n","    return precision_sum / np.sum(y_true) if np.sum(y_true) > 0 else 0"],"metadata":{"id":"IOeOiWERpKi-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### RRF Fusion Function\n"],"metadata":{"id":"BTgMQ_JVpKi-"}},{"cell_type":"code","source":["def rrf_fusion(ranked_lists, rrf_k=60):\n","    \"\"\"\n","    Perform Reciprocal Rank Fusion (RRF) on multiple ranked lists.\n","\n","    Parameters:\n","    - ranked_lists: List of lists, where each sublist contains document IDs ordered by relevance.\n","    - rrf_k: Constant to control the influence of rank.\n","\n","    Returns:\n","    - fused_docs: List of document IDs ordered by their RRF scores.\n","    \"\"\"\n","    rrf_scores = defaultdict(float)\n","    for ranked_list in ranked_lists:\n","        for rank, doc_id in enumerate(ranked_list):\n","            rrf_scores[doc_id] += 1.0 / (rrf_k + rank + 1)\n","    fused_ranking = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n","    fused_docs = [doc_id for doc_id, score in fused_ranking]\n","    return fused_docs\n"],"metadata":{"id":"yg-1pOwvpKi-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Main Retrieval and Evaluation\n"],"metadata":{"id":"cExl8zpkpKi-"}},{"cell_type":"code","source":["corpus = lyrics_df['Processed_Lyrics'].tolist()\n","bm25 = BM25(corpus)\n","\n","song_id_to_index = {song_id: idx for idx, song_id in enumerate(lyrics_df['id'])}\n","\n","all_ngrams_results = []\n","\n","query_retrievals = defaultdict(lambda: defaultdict(list))\n","\n","for n in range(1, 6):\n","    print(f\"Evaluating {n}-gram approach...\")\n","    evaluation_results = []\n","\n","    for _, row in ground_truth_df.iterrows():\n","        query = row['Processed_Query']\n","\n","        ngrams = generate_ngrams(query, n)\n","        if not ngrams:\n","            evaluation_results.append({\n","                'Query': row['query'],\n","                'N-gram': n,\n","                'Precision': 0.0,\n","                'Recall': 0.0,\n","                'F1-Score': 0.0,\n","                'Precision@3': 0.0,\n","                'Precision@6': 0.0,\n","                'Precision@10': 0.0,\n","                'Average Precision': 0.0\n","            })\n","            continue\n","\n","        doc_scores = np.zeros(len(corpus))\n","        for ng in ngrams:\n","            scores = bm25.get_scores(ng)\n","            doc_scores += np.array(scores)\n","\n","        y_true = [1 if lyrics_df.iloc[i]['id'] in relevant_ids else 0 for i in range(len(corpus))]\n","        y_pred = doc_scores\n","\n","        threshold = np.median(y_pred)\n","        binary_pred = y_pred >= threshold\n","\n","        precision = precision_score(y_true, binary_pred, zero_division=0)\n","        recall = recall_score(y_true, binary_pred, zero_division=0)\n","        f1 = f1_score(y_true, binary_pred, zero_division=0)\n","        p_at_3 = precision_at_k(y_true, y_pred, k=3)\n","        p_at_6 = precision_at_k(y_true, y_pred, k=6)\n","        p_at_10 = precision_at_k(y_true, y_pred, k=10)\n","        ap = average_precision_func(y_true, y_pred)\n","\n","        evaluation_results.append({\n","            'Query': row['query'],\n","            'N-gram': n,\n","            'Precision': precision,\n","            'Recall': recall,\n","            'F1-Score': f1,\n","            'Precision@3': p_at_3,\n","            'Precision@6': p_at_6,\n","            'Precision@10': p_at_10,\n","            'Average Precision': ap\n","        })\n","\n","        sorted_doc_indices = np.argsort(doc_scores)[-top_k:][::-1]\n","        retrieved_docs = lyrics_df.iloc[sorted_doc_indices]['id'].tolist()\n","        query_retrievals[row['query']][n] = retrieved_docs\n","\n","    evaluation_df = pd.DataFrame(evaluation_results)\n","    print(evaluation_df.head())\n","\n","    macro_results = {\n","        \"Metric\": [\n","            \"Precision\",\n","            \"Recall\",\n","            \"F1-Score\",\n","            \"Precision@3\",\n","            \"Precision@6\",\n","            \"Precision@10\",\n","            \"Average Precision\"\n","        ],\n","        \"Macro Average\": [\n","            evaluation_df['Precision'].mean(),\n","            evaluation_df['Recall'].mean(),\n","            evaluation_df['F1-Score'].mean(),\n","            evaluation_df['Precision@3'].mean(),\n","            evaluation_df['Precision@6'].mean(),\n","            evaluation_df['Precision@10'].mean(),\n","            evaluation_df['Average Precision'].mean()\n","        ]\n","    }\n","    macro_df = pd.DataFrame(macro_results)\n","    macro_df['N-gram'] = n\n","    print(f\"\\nMacro Averages for {n}-grams:\")\n","    print(macro_df)\n","\n","    evaluation_df.to_excel(f'evaluation_bm25_{n}gram.xlsx', index=False)\n","    macro_df.to_excel(f'macro_averages_{n}gram.xlsx', index=False)\n","    print(f\"\\nSaved evaluation_bm25_{n}gram.xlsx and macro_averages_{n}gram.xlsx\")\n","\n","    macro_df['N-gram'] = n\n","    all_ngrams_results.append(macro_df)\n","\n","combined_macro = pd.concat(all_ngrams_results, ignore_index=True)\n","combined_macro.to_excel('combined_macro_averages_all_ngrams.xlsx', index=False)\n","print(\"\\nAll combined macro averages have been saved to 'combined_macro_averages_all_ngrams.xlsx'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734556982268,"user_tz":-420,"elapsed":24899,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"29f8a572-27b0-4c65-eaf2-b1c1d0addaf7","id":"LDhYuZ0ypKi-"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Evaluating 1-gram approach...\n","                                               Query  N-gram  Precision  \\\n","0               Adele's song with lyrics love you in       1   0.000407   \n","1    Billie Eilish's song with lyrics stick together       1   0.000204   \n","2              Bruno Mars' song with lyrics kiss you       1   0.000407   \n","3    Jennifer Lopez's song with lyrics you feel left       1   0.000407   \n","4  Song released in 2024 with lyrics hopeless rom...       1   0.000204   \n","\n","   Recall  F1-Score  Precision@3  Precision@6  Precision@10  Average Precision  \n","0     1.0  0.000814     0.000000     0.000000           0.0           0.000602  \n","1     1.0  0.000407     0.000000     0.166667           0.1           0.250000  \n","2     1.0  0.000814     0.000000     0.000000           0.0           0.029412  \n","3     1.0  0.000814     0.000000     0.000000           0.0           0.006289  \n","4     1.0  0.000407     0.333333     0.166667           0.1           0.333333  \n","\n","Macro Averages for 1-grams:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.000432       1\n","1             Recall       1.000000       1\n","2           F1-Score       0.000863       1\n","3        Precision@3       0.146667       1\n","4        Precision@6       0.106667       1\n","5       Precision@10       0.076000       1\n","6  Average Precision       0.309028       1\n","\n","Saved evaluation_bm25_1gram.xlsx and macro_averages_1gram.xlsx\n","Evaluating 2-gram approach...\n","                                               Query  N-gram  Precision  \\\n","0               Adele's song with lyrics love you in       2   0.000000   \n","1    Billie Eilish's song with lyrics stick together       2   0.000204   \n","2              Bruno Mars' song with lyrics kiss you       2   0.000407   \n","3    Jennifer Lopez's song with lyrics you feel left       2   0.000407   \n","4  Song released in 2024 with lyrics hopeless rom...       2   0.000204   \n","\n","   Recall  F1-Score  Precision@3  Precision@6  Precision@10  Average Precision  \n","0     0.0  0.000000     0.000000     0.000000           0.0           0.000000  \n","1     1.0  0.000407     0.000000     0.166667           0.1           0.250000  \n","2     1.0  0.000814     0.000000     0.000000           0.0           0.029412  \n","3     1.0  0.000814     0.000000     0.000000           0.0           0.008850  \n","4     1.0  0.000407     0.333333     0.166667           0.1           0.333333  \n","\n","Macro Averages for 2-grams:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.000375       2\n","1             Recall       0.880000       2\n","2           F1-Score       0.000749       2\n","3        Precision@3       0.066667       2\n","4        Precision@6       0.066667       2\n","5       Precision@10       0.056000       2\n","6  Average Precision       0.192526       2\n","\n","Saved evaluation_bm25_2gram.xlsx and macro_averages_2gram.xlsx\n","Evaluating 3-gram approach...\n","                                               Query  N-gram  Precision  \\\n","0               Adele's song with lyrics love you in       3   0.000000   \n","1    Billie Eilish's song with lyrics stick together       3   0.000000   \n","2              Bruno Mars' song with lyrics kiss you       3   0.000000   \n","3    Jennifer Lopez's song with lyrics you feel left       3   0.000407   \n","4  Song released in 2024 with lyrics hopeless rom...       3   0.000000   \n","\n","   Recall  F1-Score  Precision@3  Precision@6  Precision@10  Average Precision  \n","0     0.0  0.000000          0.0          0.0           0.0           0.000000  \n","1     0.0  0.000000          0.0          0.0           0.0           0.000000  \n","2     0.0  0.000000          0.0          0.0           0.0           0.000000  \n","3     1.0  0.000814          0.0          0.0           0.0           0.006289  \n","4     0.0  0.000000          0.0          0.0           0.0           0.000000  \n","\n","Macro Averages for 3-grams:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.000187       3\n","1             Recall       0.520000       3\n","2           F1-Score       0.000374       3\n","3        Precision@3       0.066667       3\n","4        Precision@6       0.046667       3\n","5       Precision@10       0.028000       3\n","6  Average Precision       0.174020       3\n","\n","Saved evaluation_bm25_3gram.xlsx and macro_averages_3gram.xlsx\n","Evaluating 4-gram approach...\n","                                               Query  N-gram  Precision  \\\n","0               Adele's song with lyrics love you in       4        0.0   \n","1    Billie Eilish's song with lyrics stick together       4        0.0   \n","2              Bruno Mars' song with lyrics kiss you       4        0.0   \n","3    Jennifer Lopez's song with lyrics you feel left       4        0.0   \n","4  Song released in 2024 with lyrics hopeless rom...       4        0.0   \n","\n","   Recall  F1-Score  Precision@3  Precision@6  Precision@10  Average Precision  \n","0     0.0       0.0          0.0          0.0           0.0                0.0  \n","1     0.0       0.0          0.0          0.0           0.0                0.0  \n","2     0.0       0.0          0.0          0.0           0.0                0.0  \n","3     0.0       0.0          0.0          0.0           0.0                0.0  \n","4     0.0       0.0          0.0          0.0           0.0                0.0  \n","\n","Macro Averages for 4-grams:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.000106       4\n","1             Recall       0.280000       4\n","2           F1-Score       0.000212       4\n","3        Precision@3       0.026667       4\n","4        Precision@6       0.013333       4\n","5       Precision@10       0.008000       4\n","6  Average Precision       0.066492       4\n","\n","Saved evaluation_bm25_4gram.xlsx and macro_averages_4gram.xlsx\n","Evaluating 5-gram approach...\n","                                               Query  N-gram  Precision  \\\n","0               Adele's song with lyrics love you in       5        0.0   \n","1    Billie Eilish's song with lyrics stick together       5        0.0   \n","2              Bruno Mars' song with lyrics kiss you       5        0.0   \n","3    Jennifer Lopez's song with lyrics you feel left       5        0.0   \n","4  Song released in 2024 with lyrics hopeless rom...       5        0.0   \n","\n","   Recall  F1-Score  Precision@3  Precision@6  Precision@10  Average Precision  \n","0     0.0       0.0          0.0          0.0           0.0                0.0  \n","1     0.0       0.0          0.0          0.0           0.0                0.0  \n","2     0.0       0.0          0.0          0.0           0.0                0.0  \n","3     0.0       0.0          0.0          0.0           0.0                0.0  \n","4     0.0       0.0          0.0          0.0           0.0                0.0  \n","\n","Macro Averages for 5-grams:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.000049       5\n","1             Recall       0.120000       5\n","2           F1-Score       0.000098       5\n","3        Precision@3       0.000000       5\n","4        Precision@6       0.000000       5\n","5       Precision@10       0.000000       5\n","6  Average Precision       0.005016       5\n","\n","Saved evaluation_bm25_5gram.xlsx and macro_averages_5gram.xlsx\n","\n","All combined macro averages have been saved to 'combined_macro_averages_all_ngrams.xlsx'.\n"]}]},{"cell_type":"code","source":["print(\"\\nStarting Reciprocal Rank Fusion (RRF) Evaluation...\")\n","\n","rrf_evaluations = []\n","\n","for _, row in ground_truth_df.iterrows():\n","    query = row['Processed_Query']\n","    original_query = row['query']\n","    relevant_ids = set(row['Relevant_Song_IDs'])\n","\n","    ranked_lists = []\n","    for n in range(1, 6):\n","        retrieved_docs = query_retrievals[original_query].get(n, [])\n","        ranked_lists.append(retrieved_docs)\n","\n","    fused_docs = rrf_fusion(ranked_lists, rrf_k=60)\n","\n","    y_true = [1 if lyrics_df.iloc[i]['id'] in relevant_ids else 0 for i in range(len(corpus))]\n","    y_pred = [1 if doc_id in fused_docs[:top_k] else 0 for doc_id in lyrics_df['id']]\n","\n","    precision = precision_score(y_true, y_pred, zero_division=0)\n","\n","    recall = recall_score(y_true, y_pred, zero_division=0)\n","    f1 = f1_score(y_true, y_pred, zero_division=0)\n","\n","    p_at_3 = precision_at_k(y_true, [lyrics_df.iloc[song_id_to_index[doc_id]]['id'] for doc_id in fused_docs], k=3)\n","    p_at_6 = precision_at_k(y_true, [lyrics_df.iloc[song_id_to_index[doc_id]]['id'] for doc_id in fused_docs], k=6)\n","    p_at_10 = precision_at_k(y_true, [lyrics_df.iloc[song_id_to_index[doc_id]]['id'] for doc_id in fused_docs], k=10)\n","\n","    fused_scores = {doc_id: score for score, doc_id in enumerate(fused_docs, start=1)}\n","    ap = average_precision_func(\n","        [1 if doc_id in relevant_ids else 0 for doc_id in lyrics_df['id']],\n","        [fused_scores.get(doc_id, 0) for doc_id in lyrics_df['id']]\n","    )\n","\n","    rrf_evaluations.append({\n","        'Query': original_query,\n","        'Precision': precision,\n","        'Recall': recall,\n","        'F1': f1,\n","        'Precision@3': p_at_3,\n","        'Precision@6': p_at_6,\n","        'Precision@10': p_at_10,\n","        'Average Precision': ap\n","    })\n","\n","rrf_df = pd.DataFrame(rrf_evaluations)\n","print(\"\\nRRF Fused Evaluation Results:\")\n","print(rrf_df.head())\n","\n","rrf_macro_results = {\n","    \"Metric\": [\n","        \"Precision\",\n","        \"Recall\",\n","        \"F1\",\n","        \"Precision@3\",\n","        \"Precision@6\",\n","        \"Precision@10\",\n","        \"Average Precision\"\n","    ],\n","    \"Macro Average\": [\n","        rrf_df['Precision'].mean(),\n","        rrf_df['Recall'].mean(),\n","        rrf_df['F1'].mean(),\n","        rrf_df['Precision@3'].mean(),\n","        rrf_df['Precision@6'].mean(),\n","        rrf_df['Precision@10'].mean(),\n","        rrf_df['Average Precision'].mean()\n","    ]\n","}\n","rrf_macro_df = pd.DataFrame(rrf_macro_results)\n","rrf_macro_df['N-gram'] = 'RRF Fusion'\n","print(\"\\nMacro Averages for RRF Fusion:\")\n","print(rrf_macro_df)\n","\n","rrf_df.to_excel('evaluation_bm25_rrf_fusion.xlsx', index=False)\n","rrf_macro_df.to_excel('macro_averages_rrf_fusion.xlsx', index=False)\n","print(\"\\nRRF Fused evaluation results have been saved to 'evaluation_bm25_rrf_fusion.xlsx'.\")\n","print(\"Macro averages for RRF Fusion have been saved to 'macro_averages_rrf_fusion.xlsx'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mR4emB9vpKi_","executionInfo":{"status":"ok","timestamp":1734556989559,"user_tz":-420,"elapsed":7306,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"4b3ce465-6c33-4e20-f041-d98888d6bc9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Starting Reciprocal Rank Fusion (RRF) Evaluation...\n","\n","RRF Fused Evaluation Results:\n","                                               Query  Precision  Recall  \\\n","0               Adele's song with lyrics love you in        0.0     0.0   \n","1    Billie Eilish's song with lyrics stick together        0.1     1.0   \n","2              Bruno Mars' song with lyrics kiss you        0.0     0.0   \n","3    Jennifer Lopez's song with lyrics you feel left        0.0     0.0   \n","4  Song released in 2024 with lyrics hopeless rom...        0.1     1.0   \n","\n","         F1  Precision@3  Precision@6  Precision@10  Average Precision  \n","0  0.000000          0.0          0.0           0.0           0.001639  \n","1  0.181818          0.0          0.0           0.0           0.142857  \n","2  0.000000          0.0          0.0           0.0           0.000880  \n","3  0.000000          0.0          0.0           0.0           0.000419  \n","4  0.181818          0.0          0.0           0.0           0.125000  \n","\n","Macro Averages for RRF Fusion:\n","              Metric  Macro Average      N-gram\n","0          Precision       0.076000  RRF Fusion\n","1             Recall       0.500000  RRF Fusion\n","2                 F1       0.126773  RRF Fusion\n","3        Precision@3       0.000000  RRF Fusion\n","4        Precision@6       0.000000  RRF Fusion\n","5       Precision@10       0.000000  RRF Fusion\n","6  Average Precision       0.129069  RRF Fusion\n","\n","RRF Fused evaluation results have been saved to 'evaluation_bm25_rrf_fusion.xlsx'.\n","Macro averages for RRF Fusion have been saved to 'macro_averages_rrf_fusion.xlsx'.\n"]}]}]}