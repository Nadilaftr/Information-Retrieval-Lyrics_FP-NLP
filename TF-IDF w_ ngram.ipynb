{"cells":[{"cell_type":"markdown","source":["# TF-IDF with ngram"],"metadata":{"id":"YHn51fFSRBvy"}},{"cell_type":"markdown","source":["## Simple"],"metadata":{"id":"ueE3wTDjPbEV"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import warnings\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from collections import defaultdict\n","import math\n","from sklearn.metrics.pairwise import cosine_similarity\n","warnings.filterwarnings(\"ignore\")\n","\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","\n","lyrics_df = pd.read_excel('/content/databersih.xlsx')\n","ground_truth_df = pd.read_excel('/content/GT UAS NLP_simple.xlsx')\n","\n","stemmer = PorterStemmer()\n","remove_words = [\"song\", \"with\", \"lyrics\", \"from\", \"the\", \"album\", \"released\", \"in\", \"before\", \"after\", \"since\", \"s\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tGY1t3E2JJGz","executionInfo":{"status":"ok","timestamp":1734551713264,"user_tz":-420,"elapsed":1073,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"a23505d3-81b9-4ae0-b1a0-303d64433c13"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"code","source":["def clean_lyrics(text):\n","    if isinstance(text, str):\n","        text = re.sub(r'\\[.*?\\]', '', text)\n","        text = re.sub(r'\\(.*?\\)', '', text)\n","        text = re.sub(r'[^\\w\\s]', '', text)\n","        text = re.sub(r'\\d+', '', text)\n","        text = text.lower()\n","        tokens = word_tokenize(text)\n","        tokens = [stemmer.stem(word) for word in tokens if word not in remove_words]\n","        text = ' '.join(tokens)\n","    return text\n","\n","lyrics_df['Processed_Lyrics'] = lyrics_df['lyrics'].apply(clean_lyrics)\n","\n","print(\"\\nCleaned Lyrics Sample:\")\n","print(lyrics_df[['title', 'Processed_Lyrics']].head())\n","\n","def parse_song_ids(song_id_entry):\n","    if pd.isnull(song_id_entry):\n","        return []\n","    if isinstance(song_id_entry, int):\n","        return [song_id_entry]\n","    if isinstance(song_id_entry, float) and np.isnan(song_id_entry):\n","        return []\n","    song_id_str = str(song_id_entry)\n","    return [int(id_.strip()) for id_ in song_id_str.split(',') if id_.strip().isdigit()]\n","\n","ground_truth_df['Relevant_Song_IDs'] = ground_truth_df['song_id'].apply(parse_song_ids)\n","ground_truth_df = ground_truth_df[ground_truth_df['Relevant_Song_IDs'].map(len) > 0].reset_index(drop=True)\n","print(\"\\nParsed Ground Truth:\")\n","print(ground_truth_df[['query', 'Relevant_Song_IDs', 'total']].head())\n","\n","def preprocess_query(query):\n","    if isinstance(query, str):\n","        query = re.sub(r'[^\\w\\s]', '', query)\n","        query = re.sub(r'\\d+', '', query)\n","        query = query.lower()\n","        tokens = word_tokenize(query)\n","        tokens = [stemmer.stem(word) for word in tokens if word not in remove_words]\n","        return ' '.join(tokens)\n","    return query\n","\n","ground_truth_df['Processed_Query'] = ground_truth_df['query'].apply(preprocess_query)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fd-08kKLJKgH","executionInfo":{"status":"ok","timestamp":1734551755638,"user_tz":-420,"elapsed":42375,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"fdf5f2d2-2f6e-47a2-bc1f-5ce896f9791b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Cleaned Lyrics Sample:\n","                   title                                   Processed_Lyrics\n","0      Chasing Pavements  ive made up my mind dont need to think it over...\n","1          Cold Shoulder  you say it all my head and thing i think just ...\n","2         Hometown Glory  ive been walk same way as i did miss out crack...\n","3  Make You Feel My Love  when rain is blow your face and whole world is...\n","4                My Same  aye aye ayeay aye aye ayeay aye aye ayeay aye ...\n","\n","Parsed Ground Truth:\n","           query                                  Relevant_Song_IDs  total\n","0    love you in          [129, 1433, 1977, 2978, 3214, 3320, 4514]      7\n","1   home tonight  [561, 1019, 1455, 1671, 1686, 2428, 2434, 3126...     12\n","2  something new  [20, 484, 671, 783, 999, 1463, 2556, 2607, 264...     18\n","3     i held you                             [44, 1520, 4082, 4503]      4\n","4  stars tonight                                   [95, 2142, 3177]      3\n"]}]},{"cell_type":"code","source":["def precision_at_k(relevant, retrieved, k):\n","    if k == 0:\n","        return 0.0\n","    retrieved_k = retrieved[:k]\n","    relevant_retrieved = set(retrieved_k).intersection(relevant)\n","    return len(relevant_retrieved) / k\n","\n","def recall_at_k(relevant, retrieved, k):\n","    if len(relevant) == 0:\n","        return 0.0\n","    retrieved_k = retrieved[:k]\n","    relevant_retrieved = set(retrieved_k).intersection(relevant)\n","    return len(relevant_retrieved) / len(relevant)\n","\n","def f1_at_k(precision, recall):\n","    if precision + recall == 0:\n","        return 0.0\n","    return 2 * (precision * recall) / (precision + recall)\n","\n","def average_precision_func(relevant, retrieved):\n","    if len(relevant) == 0:\n","        return 0.0\n","    ap = 0.0\n","    num_relevant = 0\n","    for i, doc_id in enumerate(retrieved, start=1):\n","        if doc_id in relevant:\n","            num_relevant += 1\n","            ap += num_relevant / i\n","    return ap / len(relevant)\n","\n","def evaluate_query(relevant_ids, retrieved_docs, k_values=[3,6,10]):\n","\n","    evaluation = {}\n","    p_10 = precision_at_k(relevant_ids, retrieved_docs, 10)\n","    r_10 = recall_at_k(relevant_ids, retrieved_docs, 10)\n","    f1_10 = f1_at_k(p_10, r_10)\n","\n","    evaluation['Precision'] = p_10\n","    evaluation['Recall'] = r_10\n","    evaluation['F1'] = f1_10\n","\n","    p_3 = precision_at_k(relevant_ids, retrieved_docs, 3)\n","    p_6 = precision_at_k(relevant_ids, retrieved_docs, 6)\n","    p_10_specific = precision_at_k(relevant_ids, retrieved_docs, 10)\n","\n","    evaluation['Precision@3'] = p_3\n","    evaluation['Precision@6'] = p_6\n","    evaluation['Precision@10'] = p_10_specific\n","\n","    ap = average_precision_func(relevant_ids, retrieved_docs)\n","    evaluation['Average Precision'] = ap\n","\n","    return evaluation\n","\n","def retrieve_with_tfidf(data_df, query, ngram_range=(1,1), top_k=10):\n","    tfidf_vectorizer = TfidfVectorizer(ngram_range=ngram_range)\n","    tfidf_matrix = tfidf_vectorizer.fit_transform(data_df['Processed_Lyrics'])\n","    query_vector = tfidf_vectorizer.transform([query])\n","    cosine_sim = cosine_similarity(query_vector, tfidf_matrix).flatten()\n","    top_indices = cosine_sim.argsort()[-top_k:][::-1]\n","\n","    retrieved_docs = lyrics_df.iloc[top_indices]['id'].tolist()\n","    return retrieved_docs"],"metadata":{"id":"8qtU3lX0JOio"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k_values = [3, 6, 10]\n","top_k = 10\n","\n","all_ngram_evaluations = []\n","\n","for n in range(1, 6):\n","    evaluation_results = []\n","    for idx, row in ground_truth_df.iterrows():\n","        query = row['Processed_Query']\n","        relevant_ids = set(row['Relevant_Song_IDs'])\n","\n","        retrieved_docs = retrieve_with_tfidf(lyrics_df, query, ngram_range=(n,n), top_k=top_k)\n","        evaluation = evaluate_query(relevant_ids, retrieved_docs, k_values)\n","        evaluation['Query'] = row['query']\n","        evaluation['N-gram'] = n\n","        evaluation_results.append(evaluation)\n","\n","    eval_df = pd.DataFrame(evaluation_results)\n","    print(f\"\\nEvaluation Results for {n}-gram:\")\n","    print(eval_df.head())\n","\n","    macro_results = {\n","        \"Metric\": [\n","            \"Precision\",\n","            \"Recall\",\n","            \"F1\",\n","            \"Precision@3\",\n","            \"Precision@6\",\n","            \"Precision@10\",\n","            \"Average Precision\"\n","        ],\n","        \"Macro Average\": [\n","            eval_df['Precision'].mean(),\n","            eval_df['Recall'].mean(),\n","            eval_df['F1'].mean(),\n","            eval_df['Precision@3'].mean(),\n","            eval_df['Precision@6'].mean(),\n","            eval_df['Precision@10'].mean(),\n","            eval_df['Average Precision'].mean()\n","        ]\n","    }\n","    macro_df = pd.DataFrame(macro_results)\n","    macro_df['N-gram'] = n\n","    print(f\"\\nMacro Averages for {n}-gram:\")\n","    print(macro_df)\n","\n","    eval_df.to_excel(f'evaluation_tfidf_{n}gram.xlsx', index=False)\n","    macro_df.to_excel(f'macro_averages_{n}gram.xlsx', index=False)\n","\n","    all_ngram_evaluations.append(macro_df)\n","\n","combined_macro = pd.concat(all_ngram_evaluations, ignore_index=True)\n","combined_macro.to_excel('combined_macro_averages_all_ngrams.xlsx', index=False)\n","print(\"\\nAll macro averages for all n-grams have been saved to 'combined_macro_averages_all_ngrams.xlsx'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pz90zA5AJB-b","executionInfo":{"status":"ok","timestamp":1734552519193,"user_tz":-420,"elapsed":763574,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"9944a7aa-9cef-4673-da2d-d95245f66e35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Evaluation Results for 1-gram:\n","   Precision    Recall        F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0  0.000000  0.000000     0.000000     0.000000           0.0   \n","1        0.0  0.000000  0.000000     0.000000     0.000000           0.0   \n","2        0.2  0.111111  0.142857     0.333333     0.333333           0.2   \n","3        0.1  0.250000  0.142857     0.000000     0.000000           0.1   \n","4        0.1  0.333333  0.153846     0.000000     0.166667           0.1   \n","\n","   Average Precision          Query  N-gram  \n","0           0.000000    love you in       1  \n","1           0.000000   home tonight       1  \n","2           0.074074  something new       1  \n","3           0.031250     i held you       1  \n","4           0.066667  stars tonight       1  \n","\n","Macro Averages for 1-gram:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.088000       1\n","1             Recall       0.166111       1\n","2                 F1       0.108785       1\n","3        Precision@3       0.120000       1\n","4        Precision@6       0.133333       1\n","5       Precision@10       0.088000       1\n","6  Average Precision       0.085639       1\n","\n","Evaluation Results for 2-gram:\n","   Precision    Recall        F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0  0.000000  0.000000     0.000000     0.000000           0.0   \n","1        1.0  0.833333  0.909091     1.000000     1.000000           1.0   \n","2        1.0  0.555556  0.714286     1.000000     1.000000           1.0   \n","3        0.4  1.000000  0.571429     0.666667     0.666667           0.4   \n","4        0.3  1.000000  0.461538     1.000000     0.500000           0.3   \n","\n","   Average Precision          Query  N-gram  \n","0           0.000000    love you in       2  \n","1           0.833333   home tonight       2  \n","2           0.555556  something new       2  \n","3           0.854167     i held you       2  \n","4           1.000000  stars tonight       2  \n","\n","Macro Averages for 2-gram:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.364000       2\n","1             Recall       0.609968       2\n","2                 F1       0.420582       2\n","3        Precision@3       0.533333       2\n","4        Precision@6       0.453333       2\n","5       Precision@10       0.364000       2\n","6  Average Precision       0.530985       2\n","\n","Evaluation Results for 3-gram:\n","   Precision  Recall   F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0     0.0  0.0          0.0          0.0           0.0   \n","1        0.0     0.0  0.0          0.0          0.0           0.0   \n","2        0.0     0.0  0.0          0.0          0.0           0.0   \n","3        0.0     0.0  0.0          0.0          0.0           0.0   \n","4        0.0     0.0  0.0          0.0          0.0           0.0   \n","\n","   Average Precision          Query  N-gram  \n","0                0.0    love you in       3  \n","1                0.0   home tonight       3  \n","2                0.0  something new       3  \n","3                0.0     i held you       3  \n","4                0.0  stars tonight       3  \n","\n","Macro Averages for 3-gram:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.204000       3\n","1             Recall       0.400000       3\n","2                 F1       0.258898       3\n","3        Precision@3       0.320000       3\n","4        Precision@6       0.260000       3\n","5       Precision@10       0.204000       3\n","6  Average Precision       0.347665       3\n","\n","Evaluation Results for 4-gram:\n","   Precision  Recall   F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0     0.0  0.0          0.0          0.0           0.0   \n","1        0.0     0.0  0.0          0.0          0.0           0.0   \n","2        0.0     0.0  0.0          0.0          0.0           0.0   \n","3        0.0     0.0  0.0          0.0          0.0           0.0   \n","4        0.0     0.0  0.0          0.0          0.0           0.0   \n","\n","   Average Precision          Query  N-gram  \n","0                0.0    love you in       4  \n","1                0.0   home tonight       4  \n","2                0.0  something new       4  \n","3                0.0     i held you       4  \n","4                0.0  stars tonight       4  \n","\n","Macro Averages for 4-gram:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.032000       4\n","1             Recall       0.080000       4\n","2                 F1       0.045128       4\n","3        Precision@3       0.040000       4\n","4        Precision@6       0.046667       4\n","5       Precision@10       0.032000       4\n","6  Average Precision       0.053492       4\n","\n","Evaluation Results for 5-gram:\n","   Precision  Recall   F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0     0.0  0.0          0.0          0.0           0.0   \n","1        0.0     0.0  0.0          0.0          0.0           0.0   \n","2        0.0     0.0  0.0          0.0          0.0           0.0   \n","3        0.0     0.0  0.0          0.0          0.0           0.0   \n","4        0.0     0.0  0.0          0.0          0.0           0.0   \n","\n","   Average Precision          Query  N-gram  \n","0                0.0    love you in       5  \n","1                0.0   home tonight       5  \n","2                0.0  something new       5  \n","3                0.0     i held you       5  \n","4                0.0  stars tonight       5  \n","\n","Macro Averages for 5-gram:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.012000       5\n","1             Recall       0.040000       5\n","2                 F1       0.018462       5\n","3        Precision@3       0.040000       5\n","4        Precision@6       0.020000       5\n","5       Precision@10       0.012000       5\n","6  Average Precision       0.040000       5\n","\n","All macro averages for all n-grams have been saved to 'combined_macro_averages_all_ngrams.xlsx'.\n"]}]},{"cell_type":"code","source":["def rrf_fusion(ranked_lists, rrf_k=60):\n","    rrf_scores = defaultdict(float)\n","    for ranked_list in ranked_lists:\n","        for rank, doc_id in enumerate(ranked_list):\n","            rrf_scores[doc_id] += 1.0 / (rrf_k + rank + 1)\n","    fused_ranking = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n","    fused_docs = [doc_id for doc_id, score in fused_ranking]\n","    return fused_docs\n","\n","rrf_evaluations = []\n","\n","for idx, row in ground_truth_df.iterrows():\n","    query = row['Processed_Query']\n","    relevant_ids = set(row['Relevant_Song_IDs'])\n","\n","    ranked_lists = []\n","    for n in range(1, 6):\n","        retrieved_docs = retrieve_with_tfidf(lyrics_df, query, ngram_range=(n,n), top_k=top_k)\n","        ranked_lists.append(retrieved_docs)\n","\n","    fused_docs = rrf_fusion(ranked_lists, rrf_k=60)\n","\n","    rrf_eval = evaluate_query(relevant_ids, fused_docs, k_values)\n","    rrf_eval['Query'] = row['query']\n","    rrf_evaluations.append(rrf_eval)\n","\n","rrf_df = pd.DataFrame(rrf_evaluations)\n","print(\"\\nRRF Fused Evaluation Results:\")\n","print(rrf_df.head())\n","\n","rrf_macro_results = {\n","    \"Metric\": [\n","        \"Precision\",\n","        \"Recall\",\n","        \"F1\",\n","        \"Precision@3\",\n","        \"Precision@6\",\n","        \"Precision@10\",\n","        \"Average Precision\"\n","    ],\n","    \"Macro Average\": [\n","        rrf_df['Precision'].mean(),\n","        rrf_df['Recall'].mean(),\n","        rrf_df['F1'].mean(),\n","        rrf_df['Precision@3'].mean(),\n","        rrf_df['Precision@6'].mean(),\n","        rrf_df['Precision@10'].mean(),\n","        rrf_df['Average Precision'].mean()\n","    ]\n","}\n","rrf_macro_df = pd.DataFrame(rrf_macro_results)\n","rrf_macro_df['N-gram'] = 'RRF Fusion'\n","print(\"\\nMacro Averages for RRF Fusion:\")\n","print(rrf_macro_df)\n","\n","rrf_df.to_excel('evaluation_tfidf_rrf_fusion.xlsx', index=False)\n","rrf_macro_df.to_excel('macro_averages_rrf_fusion.xlsx', index=False)\n","print(\"\\nRRF Fused evaluation results have been saved to 'evaluation_tfidf_rrf_fusion.xlsx'.\")\n","print(\"Macro averages for RRF Fusion have been saved to 'macro_averages_rrf_fusion.xlsx'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGK1RRqjVkQ1","executionInfo":{"status":"ok","timestamp":1734554049093,"user_tz":-420,"elapsed":737998,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"outputId":"322264bc-9fea-4919-9bad-44cb7c391784"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","RRF Fused Evaluation Results:\n","   Precision  Recall   F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0     0.0  0.0          0.0          0.0           0.0   \n","1        0.0     0.0  0.0          0.0          0.0           0.0   \n","2        0.0     0.0  0.0          0.0          0.0           0.0   \n","3        0.0     0.0  0.0          0.0          0.0           0.0   \n","4        0.0     0.0  0.0          0.0          0.0           0.0   \n","\n","   Average Precision          Query  \n","0           0.000000    love you in  \n","1           0.201063   home tonight  \n","2           0.149886  something new  \n","3           0.148310     i held you  \n","4           0.148252  stars tonight  \n","\n","Macro Averages for RRF Fusion:\n","              Metric  Macro Average      N-gram\n","0          Precision       0.088000  RRF Fusion\n","1             Recall       0.187857  RRF Fusion\n","2                 F1       0.115698  RRF Fusion\n","3        Precision@3       0.106667  RRF Fusion\n","4        Precision@6       0.073333  RRF Fusion\n","5       Precision@10       0.088000  RRF Fusion\n","6  Average Precision       0.226478  RRF Fusion\n","\n","RRF Fused evaluation results have been saved to 'evaluation_tfidf_rrf_fusion.xlsx'.\n","Macro averages for RRF Fusion have been saved to 'macro_averages_rrf_fusion.xlsx'.\n"]}]},{"cell_type":"markdown","source":["## Complex"],"metadata":{"id":"zDAfuuVCKIlt"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import re\n","import warnings\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from collections import defaultdict\n","import math\n","from sklearn.metrics.pairwise import cosine_similarity\n","warnings.filterwarnings(\"ignore\")\n","\n","nltk.download('punkt')\n","nltk.download('punkt_tab')\n","\n","lyrics_df = pd.read_excel('/content/databersih.xlsx')\n","ground_truth_df = pd.read_excel('/content/GT UAS NLP_complex.xlsx')\n","\n","stemmer = PorterStemmer()\n","remove_words = [\"song\", \"with\", \"lyrics\", \"from\", \"the\", \"album\", \"released\", \"in\", \"before\", \"after\", \"since\", \"s\"]"],"metadata":{"executionInfo":{"status":"ok","timestamp":1734553386825,"user_tz":-420,"elapsed":816,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"id":"gv9SxMzzKIlu","colab":{"base_uri":"https://localhost:8080/"},"outputId":"061e392e-59a6-4e42-df78-d59feb309611"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}]},{"cell_type":"code","source":["def clean_lyrics(text):\n","    if isinstance(text, str):\n","        text = re.sub(r'\\[.*?\\]', '', text)\n","        text = re.sub(r'\\(.*?\\)', '', text)\n","        text = re.sub(r'[^\\w\\s]', '', text)\n","        text = re.sub(r'\\d+', '', text)\n","        text = text.lower()\n","        tokens = word_tokenize(text)\n","        tokens = [stemmer.stem(word) for word in tokens if word not in remove_words]\n","        text = ' '.join(tokens)\n","    return text\n","\n","lyrics_df['Processed_Lyrics'] = lyrics_df['lyrics'].apply(clean_lyrics)\n","\n","print(\"\\nCleaned Lyrics Sample:\")\n","print(lyrics_df[['title', 'Processed_Lyrics']].head())\n","\n","def parse_song_ids(song_id_entry):\n","    if pd.isnull(song_id_entry):\n","        return []\n","    if isinstance(song_id_entry, int):\n","        return [song_id_entry]\n","    if isinstance(song_id_entry, float) and np.isnan(song_id_entry):\n","        return []\n","    song_id_str = str(song_id_entry)\n","    return [int(id_.strip()) for id_ in song_id_str.split(',') if id_.strip().isdigit()]\n","\n","ground_truth_df['Relevant_Song_IDs'] = ground_truth_df['song_id'].apply(parse_song_ids)\n","ground_truth_df = ground_truth_df[ground_truth_df['Relevant_Song_IDs'].map(len) > 0].reset_index(drop=True)\n","print(\"\\nParsed Ground Truth:\")\n","print(ground_truth_df[['query', 'Relevant_Song_IDs', 'total']].head())\n","\n","def preprocess_query(query):\n","    if isinstance(query, str):\n","        query = re.sub(r'[^\\w\\s]', '', query)\n","        query = re.sub(r'\\d+', '', query)\n","        query = query.lower()\n","        tokens = word_tokenize(query)\n","        tokens = [stemmer.stem(word) for word in tokens if word not in remove_words]\n","        return ' '.join(tokens)\n","    return query\n","\n","ground_truth_df['Processed_Query'] = ground_truth_df['query'].apply(preprocess_query)"],"metadata":{"executionInfo":{"status":"ok","timestamp":1734553429551,"user_tz":-420,"elapsed":42727,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"id":"3R8fzPYUKIlv","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a7f71bd3-7344-46fb-daff-3c6002031447"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Cleaned Lyrics Sample:\n","                   title                                   Processed_Lyrics\n","0      Chasing Pavements  ive made up my mind dont need to think it over...\n","1          Cold Shoulder  you say it all my head and thing i think just ...\n","2         Hometown Glory  ive been walk same way as i did miss out crack...\n","3  Make You Feel My Love  when rain is blow your face and whole world is...\n","4                My Same  aye aye ayeay aye aye ayeay aye aye ayeay aye ...\n","\n","Parsed Ground Truth:\n","                                               query Relevant_Song_IDs  total\n","0               Adele's song with lyrics love you in            [1433]      1\n","1    Billie Eilish's song with lyrics stick together             [227]      1\n","2              Bruno Mars' song with lyrics kiss you            [2129]      1\n","3    Jennifer Lopez's song with lyrics you feel left             [788]      1\n","4  Song released in 2024 with lyrics hopeless rom...            [3019]      1\n"]}]},{"cell_type":"code","source":["# Evaluation Metrics\n","def precision_at_k(relevant, retrieved, k):\n","    if k == 0:\n","        return 0.0\n","    retrieved_k = retrieved[:k]\n","    relevant_retrieved = set(retrieved_k).intersection(relevant)\n","    return len(relevant_retrieved) / k\n","\n","def recall_at_k(relevant, retrieved, k):\n","    if len(relevant) == 0:\n","        return 0.0\n","    retrieved_k = retrieved[:k]\n","    relevant_retrieved = set(retrieved_k).intersection(relevant)\n","    return len(relevant_retrieved) / len(relevant)\n","\n","def f1_at_k(precision, recall):\n","    if precision + recall == 0:\n","        return 0.0\n","    return 2 * (precision * recall) / (precision + recall)\n","\n","def average_precision_func(relevant, retrieved):\n","    if len(relevant) == 0:\n","        return 0.0\n","    ap = 0.0\n","    num_relevant = 0\n","    for i, doc_id in enumerate(retrieved, start=1):\n","        if doc_id in relevant:\n","            num_relevant += 1\n","            ap += num_relevant / i\n","    return ap / len(relevant)\n","\n","def evaluate_query(relevant_ids, retrieved_docs, k_values=[3,6,10]):\n","    \"\"\"\n","    Evaluate a single query's results at given k-values and also compute overall P, R, F1 at k=10.\n","    \"\"\"\n","    evaluation = {}\n","    p_10 = precision_at_k(relevant_ids, retrieved_docs, 10)\n","    r_10 = recall_at_k(relevant_ids, retrieved_docs, 10)\n","    f1_10 = f1_at_k(p_10, r_10)\n","\n","    evaluation['Precision'] = p_10\n","    evaluation['Recall'] = r_10\n","    evaluation['F1'] = f1_10\n","    p_3 = precision_at_k(relevant_ids, retrieved_docs, 3)\n","    p_6 = precision_at_k(relevant_ids, retrieved_docs, 6)\n","    p_10_specific = precision_at_k(relevant_ids, retrieved_docs, 10)\n","\n","    evaluation['Precision@3'] = p_3\n","    evaluation['Precision@6'] = p_6\n","    evaluation['Precision@10'] = p_10_specific\n","\n","    ap = average_precision_func(relevant_ids, retrieved_docs)\n","    evaluation['Average Precision'] = ap\n","\n","    return evaluation\n","\n","def retrieve_with_tfidf(data_df, query, ngram_range=(1,1), top_k=10):\n","    tfidf_vectorizer = TfidfVectorizer(ngram_range=ngram_range)\n","    tfidf_matrix = tfidf_vectorizer.fit_transform(data_df['Processed_Lyrics'])\n","    query_vector = tfidf_vectorizer.transform([query])\n","    cosine_sim = cosine_similarity(query_vector, tfidf_matrix).flatten()\n","    top_indices = cosine_sim.argsort()[-top_k:][::-1]\n","\n","    retrieved_docs = lyrics_df.iloc[top_indices]['id'].tolist()\n","    return retrieved_docs"],"metadata":{"id":"U0hY86JOKIlv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["k_values = [3, 6, 10]\n","top_k = 10\n","\n","all_ngram_evaluations = []\n","\n","for n in range(1, 6):\n","    evaluation_results = []\n","    for idx, row in ground_truth_df.iterrows():\n","        query = row['Processed_Query']\n","        relevant_ids = set(row['Relevant_Song_IDs'])\n","\n","        retrieved_docs = retrieve_with_tfidf(lyrics_df, query, ngram_range=(n,n), top_k=top_k)\n","        evaluation = evaluate_query(relevant_ids, retrieved_docs, k_values)\n","        evaluation['Query'] = row['query']\n","        evaluation['N-gram'] = n\n","        evaluation_results.append(evaluation)\n","\n","    eval_df = pd.DataFrame(evaluation_results)\n","    print(f\"\\nEvaluation Results for {n}-gram:\")\n","    print(eval_df.head())\n","\n","    macro_results = {\n","        \"Metric\": [\n","            \"Precision\",\n","            \"Recall\",\n","            \"F1\",\n","            \"Precision@3\",\n","            \"Precision@6\",\n","            \"Precision@10\",\n","            \"Average Precision\"\n","        ],\n","        \"Macro Average\": [\n","            eval_df['Precision'].mean(),\n","            eval_df['Recall'].mean(),\n","            eval_df['F1'].mean(),\n","            eval_df['Precision@3'].mean(),\n","            eval_df['Precision@6'].mean(),\n","            eval_df['Precision@10'].mean(),\n","            eval_df['Average Precision'].mean()\n","        ]\n","    }\n","    macro_df = pd.DataFrame(macro_results)\n","    macro_df['N-gram'] = n\n","    print(f\"\\nMacro Averages for {n}-gram:\")\n","    print(macro_df)\n","\n","    eval_df.to_excel(f'evaluation_tfidf_{n}gram.xlsx', index=False)\n","    macro_df.to_excel(f'macro_averages_{n}gram.xlsx', index=False)\n","\n","    all_ngram_evaluations.append(macro_df)\n","\n","combined_macro = pd.concat(all_ngram_evaluations, ignore_index=True)\n","combined_macro.to_excel('combined_macro_averages_all_ngrams.xlsx', index=False)\n","print(\"\\nAll macro averages for all n-grams have been saved to 'combined_macro_averages_all_ngrams.xlsx'.\")\n"],"metadata":{"id":"L-4GgWMMKIlv","executionInfo":{"status":"ok","timestamp":1734554233626,"user_tz":-420,"elapsed":804093,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a5e01536-4ed7-4c53-a207-9dbb01e2a4d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Evaluation Results for 1-gram:\n","   Precision  Recall        F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0     0.0  0.000000     0.000000     0.000000           0.0   \n","1        0.1     1.0  0.181818     0.333333     0.166667           0.1   \n","2        0.0     0.0  0.000000     0.000000     0.000000           0.0   \n","3        0.0     0.0  0.000000     0.000000     0.000000           0.0   \n","4        0.1     1.0  0.181818     0.000000     0.166667           0.1   \n","\n","   Average Precision                                              Query  \\\n","0           0.000000               Adele's song with lyrics love you in   \n","1           0.333333    Billie Eilish's song with lyrics stick together   \n","2           0.000000              Bruno Mars' song with lyrics kiss you   \n","3           0.000000    Jennifer Lopez's song with lyrics you feel left   \n","4           0.166667  Song released in 2024 with lyrics hopeless rom...   \n","\n","   N-gram  \n","0       1  \n","1       1  \n","2       1  \n","3       1  \n","4       1  \n","\n","Macro Averages for 1-gram:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.048000       1\n","1             Recall       0.333333       1\n","2                 F1       0.081219       1\n","3        Precision@3       0.066667       1\n","4        Precision@6       0.060000       1\n","5       Precision@10       0.048000       1\n","6  Average Precision       0.148325       1\n","\n","Evaluation Results for 2-gram:\n","   Precision  Recall        F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0     0.0  0.000000     0.000000     0.000000           0.0   \n","1        0.1     1.0  0.181818     0.333333     0.166667           0.1   \n","2        0.0     0.0  0.000000     0.000000     0.000000           0.0   \n","3        0.0     0.0  0.000000     0.000000     0.000000           0.0   \n","4        0.1     1.0  0.181818     0.333333     0.166667           0.1   \n","\n","   Average Precision                                              Query  \\\n","0                0.0               Adele's song with lyrics love you in   \n","1                1.0    Billie Eilish's song with lyrics stick together   \n","2                0.0              Bruno Mars' song with lyrics kiss you   \n","3                0.0    Jennifer Lopez's song with lyrics you feel left   \n","4                0.5  Song released in 2024 with lyrics hopeless rom...   \n","\n","   N-gram  \n","0       2  \n","1       2  \n","2       2  \n","3       2  \n","4       2  \n","\n","Macro Averages for 2-gram:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.056000       2\n","1             Recall       0.486667       2\n","2                 F1       0.098974       2\n","3        Precision@3       0.133333       2\n","4        Precision@6       0.080000       2\n","5       Precision@10       0.056000       2\n","6  Average Precision       0.343333       2\n","\n","Evaluation Results for 3-gram:\n","   Precision  Recall        F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0     0.0  0.000000     0.000000     0.000000           0.0   \n","1        0.0     0.0  0.000000     0.000000     0.000000           0.0   \n","2        0.0     0.0  0.000000     0.000000     0.000000           0.0   \n","3        0.1     1.0  0.181818     0.333333     0.166667           0.1   \n","4        0.0     0.0  0.000000     0.000000     0.000000           0.0   \n","\n","   Average Precision                                              Query  \\\n","0                0.0               Adele's song with lyrics love you in   \n","1                0.0    Billie Eilish's song with lyrics stick together   \n","2                0.0              Bruno Mars' song with lyrics kiss you   \n","3                1.0    Jennifer Lopez's song with lyrics you feel left   \n","4                0.0  Song released in 2024 with lyrics hopeless rom...   \n","\n","   N-gram  \n","0       3  \n","1       3  \n","2       3  \n","3       3  \n","4       3  \n","\n","Macro Averages for 3-gram:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.064000       3\n","1             Recall       0.520000       3\n","2                 F1       0.111795       3\n","3        Precision@3       0.160000       3\n","4        Precision@6       0.093333       3\n","5       Precision@10       0.064000       3\n","6  Average Precision       0.394254       3\n","\n","Evaluation Results for 4-gram:\n","   Precision  Recall   F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0     0.0  0.0          0.0          0.0           0.0   \n","1        0.0     0.0  0.0          0.0          0.0           0.0   \n","2        0.0     0.0  0.0          0.0          0.0           0.0   \n","3        0.0     0.0  0.0          0.0          0.0           0.0   \n","4        0.0     0.0  0.0          0.0          0.0           0.0   \n","\n","   Average Precision                                              Query  \\\n","0                0.0               Adele's song with lyrics love you in   \n","1                0.0    Billie Eilish's song with lyrics stick together   \n","2                0.0              Bruno Mars' song with lyrics kiss you   \n","3                0.0    Jennifer Lopez's song with lyrics you feel left   \n","4                0.0  Song released in 2024 with lyrics hopeless rom...   \n","\n","   N-gram  \n","0       4  \n","1       4  \n","2       4  \n","3       4  \n","4       4  \n","\n","Macro Averages for 4-gram:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.024000       4\n","1             Recall       0.240000       4\n","2                 F1       0.043636       4\n","3        Precision@3       0.066667       4\n","4        Precision@6       0.033333       4\n","5       Precision@10       0.024000       4\n","6  Average Precision       0.205714       4\n","\n","Evaluation Results for 5-gram:\n","   Precision  Recall   F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0     0.0  0.0          0.0          0.0           0.0   \n","1        0.0     0.0  0.0          0.0          0.0           0.0   \n","2        0.0     0.0  0.0          0.0          0.0           0.0   \n","3        0.0     0.0  0.0          0.0          0.0           0.0   \n","4        0.0     0.0  0.0          0.0          0.0           0.0   \n","\n","   Average Precision                                              Query  \\\n","0                0.0               Adele's song with lyrics love you in   \n","1                0.0    Billie Eilish's song with lyrics stick together   \n","2                0.0              Bruno Mars' song with lyrics kiss you   \n","3                0.0    Jennifer Lopez's song with lyrics you feel left   \n","4                0.0  Song released in 2024 with lyrics hopeless rom...   \n","\n","   N-gram  \n","0       5  \n","1       5  \n","2       5  \n","3       5  \n","4       5  \n","\n","Macro Averages for 5-gram:\n","              Metric  Macro Average  N-gram\n","0          Precision       0.012000       5\n","1             Recall       0.120000       5\n","2                 F1       0.021818       5\n","3        Precision@3       0.040000       5\n","4        Precision@6       0.020000       5\n","5       Precision@10       0.012000       5\n","6  Average Precision       0.100000       5\n","\n","All macro averages for all n-grams have been saved to 'combined_macro_averages_all_ngrams.xlsx'.\n"]}]},{"cell_type":"code","source":["def rrf_fusion(ranked_lists, rrf_k=60):\n","    rrf_scores = defaultdict(float)\n","    for ranked_list in ranked_lists:\n","        for rank, doc_id in enumerate(ranked_list):\n","            rrf_scores[doc_id] += 1.0 / (rrf_k + rank + 1)\n","    fused_ranking = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)\n","    fused_docs = [doc_id for doc_id, score in fused_ranking]\n","    return fused_docs\n","\n","rrf_evaluations = []\n","\n","for idx, row in ground_truth_df.iterrows():\n","    query = row['Processed_Query']\n","    relevant_ids = set(row['Relevant_Song_IDs'])\n","\n","    ranked_lists = []\n","    for n in range(1, 6):\n","        retrieved_docs = retrieve_with_tfidf(lyrics_df, query, ngram_range=(n,n), top_k=top_k)\n","        ranked_lists.append(retrieved_docs)\n","\n","    fused_docs = rrf_fusion(ranked_lists, rrf_k=60)\n","\n","    rrf_eval = evaluate_query(relevant_ids, fused_docs, k_values)\n","    rrf_eval['Query'] = row['query']\n","    rrf_evaluations.append(rrf_eval)\n","\n","rrf_df = pd.DataFrame(rrf_evaluations)\n","print(\"\\nRRF Fused Evaluation Results:\")\n","print(rrf_df.head())\n","\n","rrf_macro_results = {\n","    \"Metric\": [\n","        \"Precision\",\n","        \"Recall\",\n","        \"F1\",\n","        \"Precision@3\",\n","        \"Precision@6\",\n","        \"Precision@10\",\n","        \"Average Precision\"\n","    ],\n","    \"Macro Average\": [\n","        rrf_df['Precision'].mean(),\n","        rrf_df['Recall'].mean(),\n","        rrf_df['F1'].mean(),\n","        rrf_df['Precision@3'].mean(),\n","        rrf_df['Precision@6'].mean(),\n","        rrf_df['Precision@10'].mean(),\n","        rrf_df['Average Precision'].mean()\n","    ]\n","}\n","rrf_macro_df = pd.DataFrame(rrf_macro_results)\n","rrf_macro_df['N-gram'] = 'RRF Fusion'\n","print(\"\\nMacro Averages for RRF Fusion:\")\n","print(rrf_macro_df)\n","\n","rrf_df.to_excel('evaluation_tfidf_rrf_fusion.xlsx', index=False)\n","rrf_macro_df.to_excel('macro_averages_rrf_fusion.xlsx', index=False)\n","print(\"\\nRRF Fused evaluation results have been saved to 'evaluation_tfidf_rrf_fusion.xlsx'.\")\n","print(\"Macro averages for RRF Fusion have been saved to 'macro_averages_rrf_fusion.xlsx'.\")\n"],"metadata":{"id":"cnEp8GZNaBd7","executionInfo":{"status":"ok","timestamp":1734555026729,"user_tz":-420,"elapsed":793107,"user":{"displayName":"Romero Musadat","userId":"09630797291190333887"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ec7e267a-d420-4c60-8208-a831542d0499"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","RRF Fused Evaluation Results:\n","   Precision  Recall   F1  Precision@3  Precision@6  Precision@10  \\\n","0        0.0     0.0  0.0          0.0          0.0           0.0   \n","1        0.0     0.0  0.0          0.0          0.0           0.0   \n","2        0.0     0.0  0.0          0.0          0.0           0.0   \n","3        0.0     0.0  0.0          0.0          0.0           0.0   \n","4        0.0     0.0  0.0          0.0          0.0           0.0   \n","\n","   Average Precision                                              Query  \n","0           0.000000               Adele's song with lyrics love you in  \n","1           0.083333    Billie Eilish's song with lyrics stick together  \n","2           0.000000              Bruno Mars' song with lyrics kiss you  \n","3           0.076923    Jennifer Lopez's song with lyrics you feel left  \n","4           0.083333  Song released in 2024 with lyrics hopeless rom...  \n","\n","Macro Averages for RRF Fusion:\n","              Metric  Macro Average      N-gram\n","0          Precision       0.036000  RRF Fusion\n","1             Recall       0.360000  RRF Fusion\n","2                 F1       0.065455  RRF Fusion\n","3        Precision@3       0.066667  RRF Fusion\n","4        Precision@6       0.033333  RRF Fusion\n","5       Precision@10       0.036000  RRF Fusion\n","6  Average Precision       0.252815  RRF Fusion\n","\n","RRF Fused evaluation results have been saved to 'evaluation_tfidf_rrf_fusion.xlsx'.\n","Macro averages for RRF Fusion have been saved to 'macro_averages_rrf_fusion.xlsx'.\n"]}]}],"metadata":{"colab":{"provenance":[{"file_id":"14rgk9FRiO-UVb82jhVzrl0lFBaBxDj4k","timestamp":1734592245330},{"file_id":"13CNdOh5ljAUBYvLUR67hXsGUi_6uFx1j","timestamp":1734527059052},{"file_id":"1MarAXFCIA1Y_Z3SpG3Bg6j1OtSgGVNE3","timestamp":1734436990444},{"file_id":"1KeTeMxQdl4TDiHxaTFn9Z4BgnaRqWuzy","timestamp":1734237352881}],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}